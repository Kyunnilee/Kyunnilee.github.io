---
layout: about
title: about
permalink: /

profile:
  align: right
  image: prof_pic.jpg
  image_circular: false # crops the image to make it circular
  more_info: >

selected_papers: False # includes a list of papers marked as "selected={true}"
social: true # includes social icons at the bottom of the page

announcements:
  enabled: true # includes a list of news items
  scrollable: true # adds a vertical scroll bar if there are more than 3 news items
  limit: 5 # leave blank to include all the news in the `_news` folder

latest_posts:
  enabled: false
  scrollable: true # adds a vertical scroll bar if there are more than 3 new posts items
  limit: 2 # leave blank to include all the blog posts
---

Hi! I am Heekyung(Anne) Lee. I am an Undergraduate Student in Computer Science at [POSTECH](https://www.postech.ac.kr/eng/), South Korea. I am also an undergraduate researcher at [Berkeley AI Research (BAIR)](https://bair.berkeley.edu/), fortunate to be supervised under [Prof. Trevor Darrell](https://people.eecs.berkeley.edu/~trevor/)'s group.

I am interested in research topics of <b>Vision</b> and <b>Language</b>, and my current work focuses on applications of vision-language models, such as image captioning, visual question answering, and multimodal reasoning.

My recent research interests are on <b>Multi-Modal Language Models</b>. 
<ul>
  <li><strong>Hallucination in Vision Language Models</strong><br>
    ∘ What is <i>hallucination</i> in Vision Language Models, and what are effective training recipes to mitigate it? How can we address hallucinations caused by misalignment between image patches and text tokens?
  </li>
  <li><strong>Real-World Evaluation of Vision Language Models</strong><br>
      ∘ What is the gap between the performance of VLMs on benchmark datasets and in real-world tasks? How do Vision Language Models respond to complex tasks, and how should we analyze their responses to guide further improvements?
  </li>
  <li><strong>LLM/VLM Agent Systems</strong><br>
      ∘ How can we design environments where LLM/VLM agents interact more responsively? How do agent systems behave differently across varying conditions?
  </li>
</ul>

Feel free to check out my [publications](/_bibliography/) and [projects](/projects/).

.

And also, lets be Strava friends! (Follow me [here](https://strava.app.link/7fH6Z2mjTTb)) I love running XD.