---
layout: about
title: about
permalink: /

profile:
  align: right
  image: prof_pic_1.jpg
  image_circular: false # crops the image to make it circular
  more_info: >

selected_papers: true # includes a list of papers marked as "selected={true}"
social: true # includes social icons at the bottom of the page

announcements:
  enabled: true # includes a list of news items
  scrollable: true # adds a vertical scroll bar if there are more than 3 news items
  limit: 5 # leave blank to include all the news in the `_news` folder

latest_posts:
  enabled: true
  scrollable: true # adds a vertical scroll bar if there are more than 3 new posts items
  limit: 3 # leave blank to include all the blog posts
---

Hi! I am Anne (Heekyung) Lee. I am an Undergraduate Student in Computer Science at [POSTECH](https://www.postech.ac.kr/eng/), South Korea. I am also an undergraduate researcher at [Berkeley AI Research (BAIR)](https://bair.berkeley.edu/), fortunate to be supervised under [Prof. Trevor Darrell](https://people.eecs.berkeley.edu/~trevor/)'s group.

I am interested in various topics in <b>Computer Vision</b> and <b>NLP</b>, with a particular focus on their applications in <b>Vision Language Models</b>, including <b>Image Captioning</b> and <b>Visual Question Answering</b> tasks.

My recent research interests are on <b>Multi-Modal Language Models</b>. 
<ul>
  <li><strong>Hallucination in Vision Language Models</strong><br>
    ∘ What is <i>hallucination</i> in Vision Language Models, and what are effective training recipes to mitigate it? How can we address hallucinations caused by misalignment between image patches and text tokens?
  </li>
  <li><strong>Real-World Evaluation of Vision Language Models</strong><br>
      ∘ What is the gap between the performance of VLMs on benchmark datasets and in real-world tasks? How do Vision Language Models respond to complex tasks, and how should we analyze their responses to guide further improvements?
  </li>
  <li><strong>LLM/VLM Agent Systems</strong><br>
      ∘ How can we design environments where LLM/VLM agents interact more responsively? How do agent systems behave differently across varying conditions?
  </li>
</ul>

Feel free to check out my [selected papers](/papers/) and [projects](/projects/).

Email: annelee5270{at}gmail{dot}com